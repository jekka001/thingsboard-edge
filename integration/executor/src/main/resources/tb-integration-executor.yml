#
# ThingsBoard, Inc. ("COMPANY") CONFIDENTIAL
#
# Copyright © 2016-2023 ThingsBoard, Inc. All Rights Reserved.
#
# NOTICE: All information contained herein is, and remains
# the property of ThingsBoard, Inc. and its suppliers,
# if any.  The intellectual and technical concepts contained
# herein are proprietary to ThingsBoard, Inc.
# and its suppliers and may be covered by U.S. and Foreign Patents,
# patents in process, and are protected by trade secret or copyright law.
#
# Dissemination of this information or reproduction of this material is strictly forbidden
# unless prior written permission is obtained from COMPANY.
#
# Access to the source code contained herein is hereby forbidden to anyone except current COMPANY employees,
# managers or contractors who have executed Confidentiality and Non-disclosure agreements
# explicitly covering such access.
#
# The copyright notice above does not evidence any actual or intended publication
# or disclosure  of  this source code, which includes
# information that is confidential and/or proprietary, and is a trade secret, of  COMPANY.
# ANY REPRODUCTION, MODIFICATION, DISTRIBUTION, PUBLIC  PERFORMANCE,
# OR PUBLIC DISPLAY OF OR THROUGH USE  OF THIS  SOURCE CODE  WITHOUT
# THE EXPRESS WRITTEN CONSENT OF COMPANY IS STRICTLY PROHIBITED,
# AND IN VIOLATION OF APPLICABLE LAWS AND INTERNATIONAL TREATIES.
# THE RECEIPT OR POSSESSION OF THIS SOURCE CODE AND/OR RELATED INFORMATION
# DOES NOT CONVEY OR IMPLY ANY RIGHTS TO REPRODUCE, DISCLOSE OR DISTRIBUTE ITS CONTENTS,
# OR TO MANUFACTURE, USE, OR SELL ANYTHING THAT IT  MAY DESCRIBE, IN WHOLE OR IN PART.
#

# Server common parameters
server:
  # Server bind address
  address: "${HTTP_BIND_ADDRESS:0.0.0.0}"
  # Server bind port
  port: "${HTTP_BIND_PORT:8082}"
  tomcat:
    # Maximum size of data that could be sent over HTTP form POST request
    max-http-form-post-size: "${MAX_HTTP_FORM_POST_SIZE:10000000}" # 10Mb

# Spring common parameters
spring.main.allow-circular-references: "true" # Spring Boot configuration property that controls whether circular dependencies between beans are allowed.

# Zookeeper connection parameters. Used for service discovery.
zk:
  # Enable/disable zookeeper discovery service.
  enabled: "${ZOOKEEPER_ENABLED:true}"
  # Zookeeper connect string
  url: "${ZOOKEEPER_URL:localhost:2181}"
  # Zookeeper retry interval in milliseconds
  retry_interval_ms: "${ZOOKEEPER_RETRY_INTERVAL_MS:3000}"
  # Zookeeper connection timeout in milliseconds
  connection_timeout_ms: "${ZOOKEEPER_CONNECTION_TIMEOUT_MS:3000}"
  # Zookeeper session timeout in milliseconds
  session_timeout_ms: "${ZOOKEEPER_SESSION_TIMEOUT_MS:3000}"
  # Name of the directory in zookeeper 'filesystem'
  zk_dir: "${ZOOKEEPER_NODES_DIR:/thingsboard}"
  # The recalculate_delay property is recommended in a microservices architecture setup for rule-engine services.
  # This property provides a pause to ensure that when a rule-engine service is restarted, other nodes don't immediately attempt to recalculate their partitions.
  # The delay is recommended because the initialization of rule chain actors is time-consuming. Avoiding unnecessary recalculations during a restart can enhance system performance and stability.
  recalculate_delay: "${ZOOKEEPER_RECALCULATE_DELAY_MS:0}"

# Integration common parameters
integrations:
  statistics:
    # Enable/disable integrations statistics
    enabled: "${INTEGRATIONS_STATISTICS_ENABLED:true}"
    # Integration statistic persistence frequency in milliseconds
    persist_frequency: "${INTEGRATIONS_STATISTICS_PERSIST_FREQUENCY:3600000}"
  reinit:
    # Enable/Disable integrations hot reinitialization
    enabled: "${INTEGRATIONS_REINIT_ENABLED:true}"
    # Checking interval for reinit integrations
    frequency: "${INTEGRATIONS_REINIT_FREQUENCY:300000}"
  rate_limits:
    # Enable/Disable integrations rate limits
    enabled: "${TB_INTEGRATION_RATE_LIMITS_ENABLED:false}"
    # The value of integrations rate limit. By default, no more than 1000 messages per second and no more 20000 messages per hour
    tenant: "${TB_INTEGRATION_RATE_LIMITS_TENANT:1000:1,20000:60}"
    # The value of integrations device rate limit. By default, no more than 10 messages per second and no more 300 messages per hour
    device: "${TB_INTEGRATION_RATE_LIMITS_DEVICE:10:1,300:60}"
  # Enable/Disable integrations local network hosts
  allow_Local_network_hosts: "${INTEGRATIONS_ALLOW_LOCAL_NETWORK_HOSTS:true}"

# Queue common parameters
queue:
  type: "${TB_QUEUE_TYPE:kafka}" # kafka (Apache Kafka) or aws-sqs (AWS SQS) or pubsub (PubSub) or service-bus (Azure Service Bus) or rabbitmq (RabbitMQ)
  prefix: "${TB_QUEUE_PREFIX:}" # Global queue prefix. Used for all topics and consumer groups. Empty by default
  kafka:
    # Kafka Bootstrap Servers
    bootstrap.servers: "${TB_KAFKA_SERVERS:localhost:9092}"
    ssl:
      # Enable/Disable SSL Kafka communication
      enabled: "${TB_KAFKA_SSL_ENABLED:false}"
      # The location of the trust store file
      truststore.location: "${TB_KAFKA_SSL_TRUSTSTORE_LOCATION:}"
      # The password of trust store file if specified
      truststore.password: "${TB_KAFKA_SSL_TRUSTSTORE_PASSWORD:}"
      # The location of the key store file. This is optional for the client and can be used for two-way authentication for the client
      keystore.location: "${TB_KAFKA_SSL_KEYSTORE_LOCATION:}"
      # The store password for the key store file. This is optional for the client and only needed if ‘ssl.keystore.location’ is configured. Key store password is not supported for PEM format
      keystore.password: "${TB_KAFKA_SSL_KEYSTORE_PASSWORD:}"
      # The password of the private key in the key store file or the PEM key specified in ‘keystore.key’
      key.password: "${TB_KAFKA_SSL_KEY_PASSWORD:}"
    # The number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the durability of records that are sent. The following settings are allowed:0,1 and all
    acks: "${TB_KAFKA_ACKS:all}"
    # Number of retries. Resend any record whose send fails with a potentially transient error
    retries: "${TB_KAFKA_RETRIES:1}"
    # The compression type for all data generated by the producer. The default is none (i.e. no compression). Valid values none or gzip
    compression.type: "${TB_KAFKA_COMPRESSION_TYPE:none}" # none or gzip
    # Default batch size. This setting gives the upper bound of the batch size to be sent
    batch.size: "${TB_KAFKA_BATCH_SIZE:16384}"
    # This variable creates a small amount of artificial delay—that is, rather than immediately sending out a record
    linger.ms: "${TB_KAFKA_LINGER_MS:1}"
    # The maximum size of a request in bytes. This setting will limit the number of record batches the producer will send in a single request to avoid sending huge requests
    max.request.size: "${TB_KAFKA_MAX_REQUEST_SIZE:1048576}"
    # The maximum number of unacknowledged requests the client will send on a single connection before blocking
    max.in.flight.requests.per.connection: "${TB_KAFKA_MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION:5}"
    # The total bytes of memory the producer can use to buffer records waiting to be sent to the server
    buffer.memory: "${TB_BUFFER_MEMORY:33554432}"
    # The multiple copies of data over the multiple brokers of Kafka
    replication_factor: "${TB_QUEUE_KAFKA_REPLICATION_FACTOR:1}"
    # The maximum delay between invocations of poll() when using consumer group management. This places an upper bound on the amount of time that the consumer can be idle before fetching more records
    max_poll_interval_ms: "${TB_QUEUE_KAFKA_MAX_POLL_INTERVAL_MS:300000}"
    # The maximum number of records returned in a single call to poll()
    max_poll_records: "${TB_QUEUE_KAFKA_MAX_POLL_RECORDS:8192}"
    # The maximum amount of data per-partition the server will return. Records are fetched in batches by the consumer
    max_partition_fetch_bytes: "${TB_QUEUE_KAFKA_MAX_PARTITION_FETCH_BYTES:16777216}"
    # The maximum amount of data the server will return. Records are fetched in batches by the consumer
    fetch_max_bytes: "${TB_QUEUE_KAFKA_FETCH_MAX_BYTES:134217728}"
    request.timeout.ms: "${TB_QUEUE_KAFKA_REQUEST_TIMEOUT_MS:30000}" # (30 seconds) # refer to https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html#producerconfigs_request.timeout.ms
    session.timeout.ms: "${TB_QUEUE_KAFKA_SESSION_TIMEOUT_MS:10000}" # (10 seconds) # refer to https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#consumerconfigs_session.timeout.ms
    # Enable/Disable using of Confluent Cloud
    use_confluent_cloud: "${TB_QUEUE_KAFKA_USE_CONFLUENT_CLOUD:false}"
    confluent:
      # The endpoint identification algorithm used by clients to validate server hostname. The default value is https
      ssl.algorithm: "${TB_QUEUE_KAFKA_CONFLUENT_SSL_ALGORITHM:https}"
      # The mechanism used to authenticate Schema Registry requests. SASL/PLAIN should only be used with TLS/SSL as a transport layer to ensure that clear passwords are not transmitted on the wire without encryption
      sasl.mechanism: "${TB_QUEUE_KAFKA_CONFLUENT_SASL_MECHANISM:PLAIN}"
      # Using JAAS Configuration for specifying multiple SASL mechanisms on a broker
      sasl.config: "${TB_QUEUE_KAFKA_CONFLUENT_SASL_JAAS_CONFIG:org.apache.kafka.common.security.plain.PlainLoginModule required username=\"CLUSTER_API_KEY\" password=\"CLUSTER_API_SECRET\";}"
      # Protocol used to communicate with brokers. Valid values are: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL
      security.protocol: "${TB_QUEUE_KAFKA_CONFLUENT_SECURITY_PROTOCOL:SASL_SSL}"
    # Key-value properties for Kafka consumer per specific topic, e.g. tb_ota_package is a topic name for ota, tb_rule_engine.sq is a topic name for default SequentialByOriginator queue.
    # Check TB_QUEUE_CORE_OTA_TOPIC and TB_QUEUE_RE_SQ_TOPIC params
    consumer-properties-per-topic:
      tb_ota_package:
        # Key-value properties for Kafka consumer per specific topic, e.g. tb_ota_package is a topic name for ota, tb_rule_engine.sq is a topic name for default SequentialByOriginator queue. Check TB_QUEUE_CORE_OTA_TOPIC and TB_QUEUE_RE_SQ_TOPIC params
        - key: max.poll.records
          # Example of specific consumer properties value per topic
          value: "${TB_QUEUE_KAFKA_OTA_MAX_POLL_RECORDS:10}"
    #      tb_rule_engine.sq:
    #        - key: max.poll.records
    #          value: "${TB_QUEUE_KAFKA_SQ_MAX_POLL_RECORDS:1024}"
    other-inline: "${TB_QUEUE_KAFKA_OTHER_PROPERTIES:}" # In this section you can specify custom parameters (semicolon separated) for Kafka consumer/producer/admin # Example "metrics.recording.level:INFO;metrics.sample.window.ms:30000"
    other: # DEPRECATED. In this section you can specify custom parameters for Kafka consumer/producer and expose the env variables to configure outside
    #  - key: "request.timeout.ms" # refer to https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html#producerconfigs_request.timeout.ms
    #    value: "${TB_QUEUE_KAFKA_REQUEST_TIMEOUT_MS:30000}" # (30 seconds)
    #  - key: "session.timeout.ms" # refer to https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#consumerconfigs_session.timeout.ms
    #    value: "${TB_QUEUE_KAFKA_SESSION_TIMEOUT_MS:10000}" # (10 seconds)
    topic-properties:
      # Kafka properties for Rule Engine
      rule-engine: "${TB_QUEUE_KAFKA_RE_TOPIC_PROPERTIES:retention.ms:604800000;segment.bytes:26214400;retention.bytes:1048576000;partitions:1;min.insync.replicas:1}"
      # Kafka properties for Core topics
      core: "${TB_QUEUE_KAFKA_CORE_TOPIC_PROPERTIES:retention.ms:604800000;segment.bytes:26214400;retention.bytes:1048576000;partitions:1;min.insync.replicas:1}"
      # Kafka properties for Transport Api topics
      transport-api: "${TB_QUEUE_KAFKA_TA_TOPIC_PROPERTIES:retention.ms:604800000;segment.bytes:26214400;retention.bytes:1048576000;partitions:10;min.insync.replicas:1}"
      # Kafka properties for Notifications topics
      notifications: "${TB_QUEUE_KAFKA_NOTIFICATIONS_TOPIC_PROPERTIES:retention.ms:604800000;segment.bytes:26214400;retention.bytes:1048576000;partitions:1;min.insync.replicas:1}"
      # Kafka properties for JS Executor topics
      js-executor: "${TB_QUEUE_KAFKA_JE_TOPIC_PROPERTIES:retention.ms:604800000;segment.bytes:26214400;retention.bytes:104857600;partitions:100;min.insync.replicas:1}"
      # Kafka properties for Integration Api topics
      integration-api: "${TB_QUEUE_KAFKA_INTEGRATION_TOPIC_PROPERTIES:retention.ms:604800000;segment.bytes:26214400;retention.bytes:1048576000;partitions:10;min.insync.replicas:1}"
    consumer-stats:
      # Prints lag between consumer group offset and last messages offset in Kafka topics
      enabled: "${TB_QUEUE_KAFKA_CONSUMER_STATS_ENABLED:true}"
      # Statistics printing interval for Kafka's consumer-groups stats
      print-interval-ms: "${TB_QUEUE_KAFKA_CONSUMER_STATS_MIN_PRINT_INTERVAL_MS:60000}"
      # Time to wait for the stats-loading requests to Kafka to finis
      kafka-response-timeout-ms: "${TB_QUEUE_KAFKA_CONSUMER_STATS_RESPONSE_TIMEOUT_MS:1000}"
  aws_sqs:
    # Use the default credentials provider for AWS SQS
    use_default_credential_provider_chain: "${TB_QUEUE_AWS_SQS_USE_DEFAULT_CREDENTIAL_PROVIDER_CHAIN:false}"
    # Access key ID from AWS IAM user
    access_key_id: "${TB_QUEUE_AWS_SQS_ACCESS_KEY_ID:YOUR_KEY}"
    # Secret access key from AWS IAM user
    secret_access_key: "${TB_QUEUE_AWS_SQS_SECRET_ACCESS_KEY:YOUR_SECRET}"
    # Region from AWS account
    region: "${TB_QUEUE_AWS_SQS_REGION:YOUR_REGION}"
    # Number of threads per each AWS SQS queue in consumer
    threads_per_topic: "${TB_QUEUE_AWS_SQS_THREADS_PER_TOPIC:1}"
    queue-properties:
      # AWS SQS queue properties. VisibilityTimeout in seconds;MaximumMessageSize in bytes;MessageRetentionPeriod in seconds
      rule-engine: "${TB_QUEUE_AWS_SQS_RE_QUEUE_PROPERTIES:VisibilityTimeout:30;MaximumMessageSize:262144;MessageRetentionPeriod:604800}"
      # AWS SQS queue properties. VisibilityTimeout in seconds;MaximumMessageSize in bytes;MessageRetentionPeriod in seconds
      core: "${TB_QUEUE_AWS_SQS_CORE_QUEUE_PROPERTIES:VisibilityTimeout:30;MaximumMessageSize:262144;MessageRetentionPeriod:604800}"
      # AWS SQS queue properties. VisibilityTimeout in seconds;MaximumMessageSize in bytes;MessageRetentionPeriod in seconds
      transport-api: "${TB_QUEUE_AWS_SQS_TA_QUEUE_PROPERTIES:VisibilityTimeout:30;MaximumMessageSize:262144;MessageRetentionPeriod:604800}"
      # AWS SQS queue properties. VisibilityTimeout in seconds;MaximumMessageSize in bytes;MessageRetentionPeriod in seconds
      notifications: "${TB_QUEUE_AWS_SQS_NOTIFICATIONS_QUEUE_PROPERTIES:VisibilityTimeout:30;MaximumMessageSize:262144;MessageRetentionPeriod:604800}"
      # VisibilityTimeout:30;MaximumMessageSize:262144;MessageRetentionPeriod:604800
      js-executor: "${TB_QUEUE_AWS_SQS_JE_QUEUE_PROPERTIES:VisibilityTimeout:30;MaximumMessageSize:262144;MessageRetentionPeriod:604800}"
      # VisibilityTimeout in seconds;MaximumMessageSize in bytes;MessageRetentionPeriod in seconds
      integration-api: "${TB_QUEUE_AWS_SQS_INTEGRATION_QUEUE_PROPERTIES:VisibilityTimeout:30;MaximumMessageSize:262144;MessageRetentionPeriod:604800}"
  pubsub:
    # Project ID from Google Cloud
    project_id: "${TB_QUEUE_PUBSUB_PROJECT_ID:YOUR_PROJECT_ID}"
    # API Credentials in JSON format
    service_account: "${TB_QUEUE_PUBSUB_SERVICE_ACCOUNT:YOUR_SERVICE_ACCOUNT}"
    max_msg_size: "${TB_QUEUE_PUBSUB_MAX_MSG_SIZE:1048576}" #in bytes
    # Number of messages per consumer
    max_messages: "${TB_QUEUE_PUBSUB_MAX_MESSAGES:1000}"
    queue-properties:
      # Pub/Sub properties for Rule Engine subscribers, messages which will commit after ackDeadlineInSec period can be consumed again
      rule-engine: "${TB_QUEUE_PUBSUB_RE_QUEUE_PROPERTIES:ackDeadlineInSec:30;messageRetentionInSec:604800}"
      # Pub/Sub properties for Core subscribers, messages which will commit after ackDeadlineInSec period can be consumed again
      core: "${TB_QUEUE_PUBSUB_CORE_QUEUE_PROPERTIES:ackDeadlineInSec:30;messageRetentionInSec:604800}"
      # Pub/Sub properties for Transport API subscribers, messages which will commit after ackDeadlineInSec period can be consumed again
      transport-api: "${TB_QUEUE_PUBSUB_TA_QUEUE_PROPERTIES:ackDeadlineInSec:30;messageRetentionInSec:604800}"
      # Pub/Sub properties for Version Control subscribers, messages which will commit after ackDeadlineInSec period can be consumed again
      notifications: "${TB_QUEUE_PUBSUB_NOTIFICATIONS_QUEUE_PROPERTIES:ackDeadlineInSec:30;messageRetentionInSec:604800}"
      # PubSub queue properties
      js-executor: "${TB_QUEUE_PUBSUB_JE_QUEUE_PROPERTIES:ackDeadlineInSec:30;messageRetentionInSec:604800}"
      # Pub/Sub properties for Transport Api subscribers, messages which will commit after ackDeadlineInSec period can be consumed again
      integration-api: "${TB_QUEUE_PUBSUB_INTEGRATION_QUEUE_PROPERTIES:ackDeadlineInSec:30;messageRetentionInSec:604800}"
  service_bus:
    # Azure namespace
    namespace_name: "${TB_QUEUE_SERVICE_BUS_NAMESPACE_NAME:YOUR_NAMESPACE_NAME}"
    # Azure Service Bus Shared Access Signatures key name
    sas_key_name: "${TB_QUEUE_SERVICE_BUS_SAS_KEY_NAME:YOUR_SAS_KEY_NAME}"
    # Azure Service Bus Shared Access Signatures key
    sas_key: "${TB_QUEUE_SERVICE_BUS_SAS_KEY:YOUR_SAS_KEY}"
    # Number of messages per a consumer
    max_messages: "${TB_QUEUE_SERVICE_BUS_MAX_MESSAGES:1000}"
    queue-properties:
      # Azure Service Bus properties for Rule Engine queues
      rule-engine: "${TB_QUEUE_SERVICE_BUS_RE_QUEUE_PROPERTIES:lockDurationInSec:30;maxSizeInMb:1024;messageTimeToLiveInSec:604800}"
      # Azure Service Bus properties for Core queues
      core: "${TB_QUEUE_SERVICE_BUS_CORE_QUEUE_PROPERTIES:lockDurationInSec:30;maxSizeInMb:1024;messageTimeToLiveInSec:604800}"
      # Azure Service Bus properties for Transport Api queues
      transport-api: "${TB_QUEUE_SERVICE_BUS_TA_QUEUE_PROPERTIES:lockDurationInSec:30;maxSizeInMb:1024;messageTimeToLiveInSec:604800}"
      # Azure Service Bus properties for Notification queues
      notifications: "${TB_QUEUE_SERVICE_BUS_NOTIFICATIONS_QUEUE_PROPERTIES:lockDurationInSec:30;maxSizeInMb:1024;messageTimeToLiveInSec:604800}"
      # Azure Service Bus queue properties
      js-executor: "${TB_QUEUE_SERVICE_BUS_JE_QUEUE_PROPERTIES:lockDurationInSec:30;maxSizeInMb:1024;messageTimeToLiveInSec:604800}"
      # Azure Service Bus properties for Integration Api queues
      integration-api: "${TB_QUEUE_SERVICE_BUS_INTEGRATION_QUEUE_PROPERTIES:lockDurationInSec:30;maxSizeInMb:1024;messageTimeToLiveInSec:604800}"
  rabbitmq:
    # By default empty
    exchange_name: "${TB_QUEUE_RABBIT_MQ_EXCHANGE_NAME:}"
    # RabbitMQ host used to establish connection
    host: "${TB_QUEUE_RABBIT_MQ_HOST:localhost}"
    # RabbitMQ host used to establish a connection
    port: "${TB_QUEUE_RABBIT_MQ_PORT:5672}"
    # Virtual hosts provide logical grouping and separation of resources
    virtual_host: "${TB_QUEUE_RABBIT_MQ_VIRTUAL_HOST:/}"
    # Username for RabbitMQ user account
    username: "${TB_QUEUE_RABBIT_MQ_USERNAME:YOUR_USERNAME}"
    # User password for RabbitMQ user account
    password: "${TB_QUEUE_RABBIT_MQ_PASSWORD:YOUR_PASSWORD}"
    # Network connection between clients and RabbitMQ nodes can fail. RabbitMQ Java client supports automatic recovery of connections and topology (queues, exchanges, bindings, and consumers)
    automatic_recovery_enabled: "${TB_QUEUE_RABBIT_MQ_AUTOMATIC_RECOVERY_ENABLED:false}"
    # The connection timeout for the RabbitMQ connection factory
    connection_timeout: "${TB_QUEUE_RABBIT_MQ_CONNECTION_TIMEOUT:60000}"
    # RabbitMQ has a timeout for connection handshake. When clients run in heavily constrained environments, it may be necessary to increase the timeout
    handshake_timeout: "${TB_QUEUE_RABBIT_MQ_HANDSHAKE_TIMEOUT:10000}"
    queue-properties:
      # RabbitMQ properties for Rule Engine queues
      rule-engine: "${TB_QUEUE_RABBIT_MQ_RE_QUEUE_PROPERTIES:x-max-length-bytes:1048576000;x-message-ttl:604800000}"
      # RabbitMQ properties for Core queues
      core: "${TB_QUEUE_RABBIT_MQ_CORE_QUEUE_PROPERTIES:x-max-length-bytes:1048576000;x-message-ttl:604800000}"
      # RabbitMQ properties for Transport API queues
      transport-api: "${TB_QUEUE_RABBIT_MQ_TA_QUEUE_PROPERTIES:x-max-length-bytes:1048576000;x-message-ttl:604800000}"
      # RabbitMQ properties for Notification queues
      notifications: "${TB_QUEUE_RABBIT_MQ_NOTIFICATIONS_QUEUE_PROPERTIES:x-max-length-bytes:1048576000;x-message-ttl:604800000}"
      # RabbitMQ queue properties
      js-executor: "${TB_QUEUE_RABBIT_MQ_JE_QUEUE_PROPERTIES:x-max-length-bytes:1048576000;x-message-ttl:604800000}"
      # RabbitMQ properties for Integration Api queues
      integration-api: "${TB_QUEUE_RABBIT_MQ_INTEGRATION_QUEUE_PROPERTIES:x-max-length-bytes:1048576000;x-message-ttl:604800000}"
  partitions:
    hash_function_name: "${TB_QUEUE_PARTITIONS_HASH_FUNCTION_NAME:murmur3_128}" # murmur3_32, murmur3_128 or sha256
  transport_api:
    # Topic used to consume api requests from transport microservices
    requests_topic: "${TB_QUEUE_TRANSPORT_API_REQUEST_TOPIC:tb_transport.api.requests}"
    # Topic used to produce api responses to transport microservices
    responses_topic: "${TB_QUEUE_TRANSPORT_API_RESPONSE_TOPIC:tb_transport.api.responses}"
    # Maximum pending api requests from transport microservices to be handled by server
    max_pending_requests: "${TB_QUEUE_TRANSPORT_MAX_PENDING_REQUESTS:10000}"
    # Maximum timeout in milliseconds to handle api request from transport microservice by server
    max_requests_timeout: "${TB_QUEUE_TRANSPORT_MAX_REQUEST_TIMEOUT:10000}"
    # Amount of threads used to invoke callbacks
    max_callback_threads: "${TB_QUEUE_TRANSPORT_MAX_CALLBACK_THREADS:100}"
    # Interval in milliseconds to poll api requests from transport microservices
    request_poll_interval: "${TB_QUEUE_TRANSPORT_REQUEST_POLL_INTERVAL_MS:25}"
    # Interval in milliseconds to poll api response from transport microservices
    response_poll_interval: "${TB_QUEUE_TRANSPORT_RESPONSE_POLL_INTERVAL_MS:25}"
  core:
    # Default topic name of Kafka, RabbitMQ, etc. queue
    topic: "${TB_QUEUE_CORE_TOPIC:tb_core}"
    # Interval in milliseconds to poll messages by Core microservices
    poll-interval: "${TB_QUEUE_CORE_POLL_INTERVAL_MS:25}"
    # Amount of partitions used by Core microservices
    partitions: "${TB_QUEUE_CORE_PARTITIONS:10}"
    # Timeout for processing a message pack by Core microservices
    pack-processing-timeout: "${TB_QUEUE_CORE_PACK_PROCESSING_TIMEOUT_MS:2000}"
    ota:
      # Default topic name for OTA updates
      topic: "${TB_QUEUE_CORE_OTA_TOPIC:tb_ota_package}"
      # The interval of processing the OTA updates for devices. Used to avoid any harm to the network due to many parallel OTA updates
      pack-interval-ms: "${TB_QUEUE_CORE_OTA_PACK_INTERVAL_MS:60000}"
      # The size of OTA updates notifications fetched from the queue. The queue stores pairs of firmware and device ids
      pack-size: "${TB_QUEUE_CORE_OTA_PACK_SIZE:100}"
    # Stats topic name for queue Kafka, RabbitMQ, etc.
    usage-stats-topic: "${TB_QUEUE_US_TOPIC:tb_usage_stats}"
    stats:
      # Enable/disable statistics for Core microservices
      enabled: "${TB_QUEUE_CORE_STATS_ENABLED:true}"
      # Statistics printing interval for Core microservices
      print-interval-ms: "${TB_QUEUE_CORE_STATS_PRINT_INTERVAL_MS:60000}"
  js:
    # JS Eval request topic
    request_topic: "${REMOTE_JS_EVAL_REQUEST_TOPIC:js_eval.requests}"
    # JS Eval responses topic prefix that is combined with node id
    response_topic_prefix: "${REMOTE_JS_EVAL_RESPONSE_TOPIC:js_eval.responses}"
    # JS Eval max pending requests
    max_pending_requests: "${REMOTE_JS_MAX_PENDING_REQUESTS:10000}"
    # JS Eval max request timeout
    max_eval_requests_timeout: "${REMOTE_JS_MAX_EVAL_REQUEST_TIMEOUT:60000}"
    # JS max request timeout
    max_requests_timeout: "${REMOTE_JS_MAX_REQUEST_TIMEOUT:10000}"
    # JS response poll interval
    response_poll_interval: "${REMOTE_JS_RESPONSE_POLL_INTERVAL_MS:25}"
  rule-engine:
    # Deprecated. It will be removed in the nearest releases
    topic: "${TB_QUEUE_RULE_ENGINE_TOPIC:tb_rule_engine}"
    # Interval in milliseconds to poll messages by Rule Engine
    poll-interval: "${TB_QUEUE_RULE_ENGINE_POLL_INTERVAL_MS:25}"
    # Timeout for processing a message pack of Rule Engine
    pack-processing-timeout: "${TB_QUEUE_RULE_ENGINE_PACK_PROCESSING_TIMEOUT_MS:2000}"
    stats:
      # Enable/disable statistics for Rule Engine
      enabled: "${TB_QUEUE_RULE_ENGINE_STATS_ENABLED:true}"
      # Statistics printing interval for Rule Engine
      print-interval-ms: "${TB_QUEUE_RULE_ENGINE_STATS_PRINT_INTERVAL_MS:60000}"
    queues:
      - name: "${TB_QUEUE_RE_MAIN_QUEUE_NAME:Main}" # queue name
        topic: "${TB_QUEUE_RE_MAIN_TOPIC:tb_rule_engine.main}" # queue topic
        poll-interval: "${TB_QUEUE_RE_MAIN_POLL_INTERVAL_MS:25}" # poll interval
        partitions: "${TB_QUEUE_RE_MAIN_PARTITIONS:10}" # number queue partitions
        consumer-per-partition: "${TB_QUEUE_RE_MAIN_CONSUMER_PER_PARTITION:true}" # if true - use for each customer different partition
        pack-processing-timeout: "${TB_QUEUE_RE_MAIN_PACK_PROCESSING_TIMEOUT_MS:2000}" # Timeout for processing a message pack
        submit-strategy:
          type: "${TB_QUEUE_RE_MAIN_SUBMIT_STRATEGY_TYPE:BURST}" # BURST, BATCH, SEQUENTIAL_BY_ORIGINATOR, SEQUENTIAL_BY_TENANT, SEQUENTIAL
          # For BATCH only
          batch-size: "${TB_QUEUE_RE_MAIN_SUBMIT_STRATEGY_BATCH_SIZE:1000}" # Maximum number of messages in batch
        processing-strategy:
          type: "${TB_QUEUE_RE_MAIN_PROCESSING_STRATEGY_TYPE:SKIP_ALL_FAILURES}" # SKIP_ALL_FAILURES, SKIP_ALL_FAILURES_AND_TIMED_OUT, RETRY_ALL, RETRY_FAILED, RETRY_TIMED_OUT, RETRY_FAILED_AND_TIMED_OUT
          # For RETRY_ALL, RETRY_FAILED, RETRY_TIMED_OUT, RETRY_FAILED_AND_TIMED_OUT
          retries: "${TB_QUEUE_RE_MAIN_PROCESSING_STRATEGY_RETRIES:3}" # Number of retries, 0 is unlimited
          failure-percentage: "${TB_QUEUE_RE_MAIN_PROCESSING_STRATEGY_FAILURE_PERCENTAGE:0}" # Skip retry if failures or timeouts are less then X percentage of messages;
          pause-between-retries: "${TB_QUEUE_RE_MAIN_PROCESSING_STRATEGY_RETRY_PAUSE:3}" # Time in seconds to wait in consumer thread before retries;
          max-pause-between-retries: "${TB_QUEUE_RE_MAIN_PROCESSING_STRATEGY_MAX_RETRY_PAUSE:3}" # Max allowed time in seconds for pause between retries.
      - name: "${TB_QUEUE_RE_HP_QUEUE_NAME:HighPriority}" # queue name
        topic: "${TB_QUEUE_RE_HP_TOPIC:tb_rule_engine.hp}" # queue topic
        poll-interval: "${TB_QUEUE_RE_HP_POLL_INTERVAL_MS:25}" # poll interval
        partitions: "${TB_QUEUE_RE_HP_PARTITIONS:10}"  # number queue partitions
        consumer-per-partition: "${TB_QUEUE_RE_HP_CONSUMER_PER_PARTITION:true}" # if true - use for each customer different partition
        pack-processing-timeout: "${TB_QUEUE_RE_HP_PACK_PROCESSING_TIMEOUT_MS:2000}" # Timeout for processing a message pack
        submit-strategy:
          type: "${TB_QUEUE_RE_HP_SUBMIT_STRATEGY_TYPE:BURST}" # BURST, BATCH, SEQUENTIAL_BY_ORIGINATOR, SEQUENTIAL_BY_TENANT, SEQUENTIAL
          # For BATCH only
          batch-size: "${TB_QUEUE_RE_HP_SUBMIT_STRATEGY_BATCH_SIZE:100}" # Maximum number of messages in batch
        processing-strategy:
          type: "${TB_QUEUE_RE_HP_PROCESSING_STRATEGY_TYPE:RETRY_FAILED_AND_TIMED_OUT}" # SKIP_ALL_FAILURES, SKIP_ALL_FAILURES_AND_TIMED_OUT, RETRY_ALL, RETRY_FAILED, RETRY_TIMED_OUT, RETRY_FAILED_AND_TIMED_OUT
          # For RETRY_ALL, RETRY_FAILED, RETRY_TIMED_OUT, RETRY_FAILED_AND_TIMED_OUT
          retries: "${TB_QUEUE_RE_HP_PROCESSING_STRATEGY_RETRIES:0}" # Number of retries, 0 is unlimited
          failure-percentage: "${TB_QUEUE_RE_HP_PROCESSING_STRATEGY_FAILURE_PERCENTAGE:0}" # Skip retry if failures or timeouts are less then X percentage of messages;
          pause-between-retries: "${TB_QUEUE_RE_HP_PROCESSING_STRATEGY_RETRY_PAUSE:5}" # Time in seconds to wait in consumer thread before retries;
          max-pause-between-retries: "${TB_QUEUE_RE_HP_PROCESSING_STRATEGY_MAX_RETRY_PAUSE:5}" # Max allowed time in seconds for pause between retries.
      - name: "${TB_QUEUE_RE_SQ_QUEUE_NAME:SequentialByOriginator}" # queue name
        topic: "${TB_QUEUE_RE_SQ_TOPIC:tb_rule_engine.sq}" # queue topic
        poll-interval: "${TB_QUEUE_RE_SQ_POLL_INTERVAL_MS:25}" # poll interval
        partitions: "${TB_QUEUE_RE_SQ_PARTITIONS:10}" # number queue partitions
        consumer-per-partition: "${TB_QUEUE_RE_SQ_CONSUMER_PER_PARTITION:true}" # if true - use for each customer different partition
        pack-processing-timeout: "${TB_QUEUE_RE_SQ_PACK_PROCESSING_TIMEOUT_MS:2000}" # Timeout for processing a message pack
        submit-strategy:
          type: "${TB_QUEUE_RE_SQ_SUBMIT_STRATEGY_TYPE:SEQUENTIAL_BY_ORIGINATOR}" # BURST, BATCH, SEQUENTIAL_BY_ORIGINATOR, SEQUENTIAL_BY_TENANT, SEQUENTIAL
          # For BATCH only
          batch-size: "${TB_QUEUE_RE_SQ_SUBMIT_STRATEGY_BATCH_SIZE:100}" # Maximum number of messages in batch
        processing-strategy:
          type: "${TB_QUEUE_RE_SQ_PROCESSING_STRATEGY_TYPE:RETRY_FAILED_AND_TIMED_OUT}" # SKIP_ALL_FAILURES, SKIP_ALL_FAILURES_AND_TIMED_OUT, RETRY_ALL, RETRY_FAILED, RETRY_TIMED_OUT, RETRY_FAILED_AND_TIMED_OUT
          # For RETRY_ALL, RETRY_FAILED, RETRY_TIMED_OUT, RETRY_FAILED_AND_TIMED_OUT
          retries: "${TB_QUEUE_RE_SQ_PROCESSING_STRATEGY_RETRIES:3}" # Number of retries, 0 is unlimited
          failure-percentage: "${TB_QUEUE_RE_SQ_PROCESSING_STRATEGY_FAILURE_PERCENTAGE:0}" # Skip retry if failures or timeouts are less then X percentage of messages;
          pause-between-retries: "${TB_QUEUE_RE_SQ_PROCESSING_STRATEGY_RETRY_PAUSE:5}" # Time in seconds to wait in consumer thread before retries;
          max-pause-between-retries: "${TB_QUEUE_RE_SQ_PROCESSING_STRATEGY_MAX_RETRY_PAUSE:5}" # Max allowed time in seconds for pause between retries.
  integration:
    # Name of hash function used for consistent hash ring in Cluster Mode. See architecture docs for more details. Valid values - murmur3_32, murmur3_128 or sha256
    partitions: "${TB_QUEUE_INTEGRATION_PARTITIONS:3}"
    # Default notification topic name used by queue
    notifications_topic: "${TB_QUEUE_INTEGRATION_NOTIFICATIONS_TOPIC:tb_ie.notifications}"
    # Default downlink topic name used by queue
    downlink_topic: "${TB_QUEUE_INTEGRATION_DOWNLINK_TOPIC:tb_ie.downlink}"
    # Default uplink topic name used by queue
    uplink_topic: "${TB_QUEUE_INTEGRATION_UPLINK_TOPIC:tb_ie.uplink}"
    # Interval in milliseconds to poll messages by integrations
    poll_interval: "${TB_QUEUE_INTEGRATION_POLL_INTERVAL_MS:25}"
    # Timeout for processing a message pack by integrations
    pack-processing-timeout: "${TB_QUEUE_INTEGRATION_PACK_PROCESSING_TIMEOUT_MS:10000}"
  integration_api:
    # Default Integration Api request topic name used by queue
    requests_topic: "${TB_QUEUE_INTEGRATION_EXECUTOR_API_REQUEST_TOPIC:tb_ie.api.requests}"
    # Default Integration Api response topic name used by queue
    responses_topic: "${TB_QUEUE_INTEGRATION_EXECUTOR_API_RESPONSE_TOPIC:tb_ie.api.responses}"
    # Maximum pending api requests from integration executor to be handled by server<
    max_pending_requests: "${TB_QUEUE_INTEGRATION_EXECUTOR_MAX_PENDING_REQUESTS:10000}"
    # Maximum timeout in milliseconds to handle api request from integration executor microservice by server
    max_requests_timeout: "${TB_QUEUE_INTEGRATION_EXECUTOR_MAX_REQUEST_TIMEOUT:10000}"
    # Amount of threads used to invoke callbacks
    max_callback_threads: "${TB_QUEUE_INTEGRATION_EXECUTOR_MAX_CALLBACK_THREADS:10}"
    # Interval in milliseconds to poll api requests from integration executor microservices
    request_poll_interval: "${TB_QUEUE_INTEGRATION_EXECUTOR_REQUEST_POLL_INTERVAL_MS:25}"
    # Interval in milliseconds to poll api response from integration executor microservices
    response_poll_interval: "${TB_QUEUE_INTEGRATION_EXECUTOR_RESPONSE_POLL_INTERVAL_MS:25}"

# Tbel parameters
tbel:
  # Enable/Disable TBEL feature.
  enabled: "${TBEL_ENABLED:true}"
  # Limit the number of arguments that are passed to the function to execute the script
  max_total_args_size: "${TBEL_MAX_TOTAL_ARGS_SIZE:100000}"
  # Maximum allowed symbols in a result after processing a script
  max_result_size: "${TBEL_MAX_RESULT_SIZE:300000}"
  # Maximum allowed symbols in the script body
  max_script_body_size: "${TBEL_MAX_SCRIPT_BODY_SIZE:50000}"
  # Maximum allowed TBEL script execution memory
  max_memory_limit_mb: "${TBEL_MAX_MEMORY_LIMIT_MB: 8}"
  # Maximum allowed TBEL script execution errors before it will be blacklisted
  max_errors: "${TBEL_MAX_ERRORS:3}"
  # TBEL Eval max request timeout in milliseconds. 0 - no timeout
  max_requests_timeout: "${TBEL_MAX_REQUEST_TIMEOUT:500}"
  # Maximum time in seconds for black listed function to stay in the list.
  max_black_list_duration_sec: "${TBEL_MAX_BLACKLIST_DURATION_SEC:60}"
  # Specify thread pool size for javascript executor service
  thread_pool_size: "${TBEL_THREAD_POOL_SIZE:50}"
  stats:
    # Enable/Disable stats collection for TBEL engine
    enabled: "${TB_TBEL_STATS_ENABLED:false}"
    # Interval of logging for TBEL stats
    print_interval_ms: "${TB_TBEL_STATS_PRINT_INTERVAL_MS:10000}"

# JS parameters
js:
  evaluator: "${JS_EVALUATOR:local}" # local/remote
  # Built-in JVM JavaScript environment properties
  local:
    # Specify thread pool size for javascript executor service
    js_thread_pool_size: "${LOCAL_JS_THREAD_POOL_SIZE:50}"
    # Use Sandboxed (secured) JVM JavaScript environment
    use_js_sandbox: "${USE_LOCAL_JS_SANDBOX:true}"
    # Specify thread pool size for JavaScript sandbox resource monitor
    monitor_thread_pool_size: "${LOCAL_JS_SANDBOX_MONITOR_THREAD_POOL_SIZE:4}"
    # Maximum CPU time in milliseconds allowed for script execution
    max_cpu_time: "${LOCAL_JS_SANDBOX_MAX_CPU_TIME:8000}"
    # Maximum allowed JavaScript execution errors before JavaScript will be blacklisted
    max_errors: "${LOCAL_JS_SANDBOX_MAX_ERRORS:3}"
    # JS Eval max request timeout. 0 - no timeout
    max_requests_timeout: "${LOCAL_JS_MAX_REQUEST_TIMEOUT:0}"
    # Maximum time in seconds for black listed function to stay in the list.
    max_black_list_duration_sec: "${LOCAL_JS_SANDBOX_MAX_BLACKLIST_DURATION_SEC:60}"
    stats:
      # Enable/Disable stats collection for local JS executor
      enabled: "${TB_JS_LOCAL_STATS_ENABLED:false}"
      # Interval of logging for local JS executor stats
      print_interval_ms: "${TB_JS_LOCAL_STATS_PRINT_INTERVAL_MS:10000}"
  # Remote JavaScript environment properties
  remote:
    # Specify thread pool size for javascript executor service
    js_thread_pool_size: "${REMOTE_JS_THREAD_POOL_SIZE:50}"
    # Maximum allowed JavaScript execution errors before JavaScript will be blacklisted
    max_errors: "${REMOTE_JS_SANDBOX_MAX_ERRORS:3}"
    # Maximum time in seconds for black listed function to stay in the list.
    max_black_list_duration_sec: "${REMOTE_JS_SANDBOX_MAX_BLACKLIST_DURATION_SEC:60}"
    stats:
      # Enable/Disable stats collection for remote JS executor
      enabled: "${TB_JS_REMOTE_STATS_ENABLED:false}"
      # Interval of logging for remote JS executor stats
      print_interval_ms: "${TB_JS_REMOTE_STATS_PRINT_INTERVAL_MS:10000}"

# Cache parameters
cache:
  # caffeine or redis
  type: "${CACHE_TYPE:redis}"
  maximumPoolSize: "${CACHE_MAXIMUM_POOL_SIZE:16}" # max pool size to process futures that calls the external cache
  specs:
    devices:
      timeToLiveInMinutes: "${CACHE_SPECS_DEVICES_TTL:1440}" # Device cache TTL
      maxSize: "${CACHE_SPECS_DEVICES_MAX_SIZE:10000}" # 0 means the cache is disabled
    # PE cache specs
    downlink:
      timeToLiveInMinutes: "${CACHE_SPECS_DOWNLINK_TTL:1440}" # Downlink converter cache specs TTL
      maxSize: "${CACHE_SPECS_DOWNLINK_MAX_SIZE:100000}" # 0 means the cache is disabled
    integrations:
      timeToLiveInMinutes: "${CACHE_SPECS_INTEGRATIONS_TTL:1440}" # integrations cache specs TTL
      maxSize: "${CACHE_SPECS_INTEGRATIONS_MAX_SIZE:10000}" # 0 means the cache is disabled

  # deliberately placed outside 'specs' group above
  rateLimits:
    timeToLiveInMinutes: "${CACHE_SPECS_RATE_LIMITS_TTL:60}" # Rate limits cache TTL
    maxSize: "${CACHE_SPECS_RATE_LIMITS_MAX_SIZE:100000}" # 0 means the cache is disabled


# Redis parameters
redis:
  connection:
    # standalone or cluster
    type: "${REDIS_CONNECTION_TYPE:standalone}"
  standalone:
    # Redis connection host
    host: "${REDIS_HOST:localhost}"
    # Redis connection port
    port: "${REDIS_PORT:6379}"
    # Use the default Redis configuration file
    useDefaultClientConfig: "${REDIS_USE_DEFAULT_CLIENT_CONFIG:true}"
    # this value may be used only if you used not default ClientConfig
    clientName: "${REDIS_CLIENT_NAME:standalone}"
    # this value may be used only if you used not default ClientConfig
    connectTimeout: "${REDIS_CLIENT_CONNECT_TIMEOUT:30000}"
    # this value may be used only if you used not default ClientConfig
    readTimeout: "${REDIS_CLIENT_READ_TIMEOUT:60000}"
    # this value may be used only if you used not default ClientConfig
    usePoolConfig: "${REDIS_CLIENT_USE_POOL_CONFIG:false}"
  cluster:
    # Comma-separated list of "host:port" pairs to bootstrap from.
    nodes: "${REDIS_NODES:}"
    # Maximum number of redirects to follow when executing commands across the cluster.
    max-redirects: "${REDIS_MAX_REDIRECTS:12}"
    # if set false will be used pool config build from values of the pool config section
    useDefaultPoolConfig: "${REDIS_USE_DEFAULT_POOL_CONFIG:true}"
  # db index
  db: "${REDIS_DB:0}"
  # db password
  password: "${REDIS_PASSWORD:}"
  # pool config
  pool_config:
    # Maximum number of connections that can be allocated by the connection pool
    maxTotal: "${REDIS_POOL_CONFIG_MAX_TOTAL:128}"
    # Maximum number of idle connections that can be maintained in the pool without being closed
    maxIdle: "${REDIS_POOL_CONFIG_MAX_IDLE:128}"
    # Minumum number of idle connections that can be maintained in the pool without being closed
    minIdle: "${REDIS_POOL_CONFIG_MIN_IDLE:16}"
    # Enable/Disable PING command sent when a connection is borrowed
    testOnBorrow: "${REDIS_POOL_CONFIG_TEST_ON_BORROW:true}"
    # The property is used to specify whether to test the connection before returning it to the connection pool.
    testOnReturn: "${REDIS_POOL_CONFIG_TEST_ON_RETURN:true}"
    # The property is used in the context of connection pooling in Redis
    testWhileIdle: "${REDIS_POOL_CONFIG_TEST_WHILE_IDLE:true}"
    # Minimum time that an idle connection should be idle before it can be evicted from the connection pool. The value is set in milliseconds
    minEvictableMs: "${REDIS_POOL_CONFIG_MIN_EVICTABLE_MS:60000}"
    # Specifies the time interval in milliseconds between two consecutive eviction runs
    evictionRunsMs: "${REDIS_POOL_CONFIG_EVICTION_RUNS_MS:30000}"
    # Maximum time in milliseconds where a client is willing to wait for a connection from the pool when all connections are exhausted
    maxWaitMills: "${REDIS_POOL_CONFIG_MAX_WAIT_MS:60000}"
    # Specifies the number of connections to test for eviction during each eviction run
    numberTestsPerEvictionRun: "${REDIS_POOL_CONFIG_NUMBER_TESTS_PER_EVICTION_RUN:3}"
    # Determines the behavior when a thread requests a connection from the pool, but there are no available connections, and the pool cannot create more due to the maxTotal configuration
    blockWhenExhausted: "${REDIS_POOL_CONFIG_BLOCK_WHEN_EXHAUSTED:true}"

# CoAP server parameters
coap:
  # Enable/disable coap transport protocol.
  enabled: "${COAP_ENABLED:true}"
  # CoAP bind address
  bind_address: "${COAP_BIND_ADDRESS:0.0.0.0}"
  # CoAP bind port
  bind_port: "${COAP_BIND_PORT:5683}"
  dtls:
    # Enable/disable DTLS 1.2 support
    enabled: "${COAP_DTLS_ENABLED:false}"
    # RFC7925_RETRANSMISSION_TIMEOUT_IN_MILLISECONDS = 9000
    retransmission_timeout: "${COAP_DTLS_RETRANSMISSION_TIMEOUT_IN_MILLISECONDS:9000}"
    # CoAP DTLS bind address
    bind_address: "${COAP_DTLS_BIND_ADDRESS:0.0.0.0}"
    # CoAP DTLS bind port
    bind_port: "${COAP_DTLS_BIND_PORT:5684}"
    # Server DTLS credentials
    credentials:
      # Server credentials type (PEM - pem certificate file; KEYSTORE - java keystore)
      type:  "${COAP_DTLS_CREDENTIALS_TYPE:PEM}"
      # PEM server credentials
      pem:
        # Path to the server certificate file (holds server certificate or certificate chain, may include server private key)
        cert_file: "${COAP_DTLS_PEM_CERT:coapserver.pem}"
        # Path to the server certificate private key file. Optional by default. Required if the private key is not present in server certificate file;
        key_file: "${COAP_DTLS_PEM_KEY:coapserver_key.pem}"
        # Server certificate private key password (optional)
        key_password: "${COAP_DTLS_PEM_KEY_PASSWORD:server_key_password}"
      # Keystore server credentials
      keystore:
        # Type of the key store (JKS or PKCS12)
        type: "${COAP_DTLS_KEY_STORE_TYPE:JKS}"
        # Path to the key store that holds the SSL certificate
        store_file: "${COAP_DTLS_KEY_STORE:coapserver.jks}"
        # Password used to access the key store
        store_password: "${COAP_DTLS_KEY_STORE_PASSWORD:server_ks_password}"
        # Key alias
        key_alias: "${COAP_DTLS_KEY_ALIAS:serveralias}"
        # Password used to access the key
        key_password: "${COAP_DTLS_KEY_PASSWORD:server_key_password}"
    x509:
      # Skip certificate validity check for client certificates.
      skip_validity_check_for_client_cert: "${TB_COAP_X509_DTLS_SKIP_VALIDITY_CHECK_FOR_CLIENT_CERT:false}"
      # Inactivity timeout of DTLS session. Used to cleanup cache
      dtls_session_inactivity_timeout: "${TB_COAP_X509_DTLS_SESSION_INACTIVITY_TIMEOUT:86400000}"
      # Interval of periodic eviction of the timed-out DTLS sessions
      dtls_session_report_timeout: "${TB_COAP_X509_DTLS_SESSION_REPORT_TIMEOUT:1800000}"

# Event parameters
event:
  debug:
    rate_limits:
      # If true rate limits will be active
      enabled: "${DEBUG_MODE_RATE_LIMITS_PER_TENANT_ENABLED:true}"
      # No more than 50000 messages per hour
      integration: "${INTEGRATION_DEBUG_MODE_RATE_LIMITS_PER_TENANT:50000:3600}"
      # No more than 50000 messages per hour
      converter: "${CONVERTER_DEBUG_MODE_RATE_LIMITS_PER_TENANT:50000:3600}"

 # Service parameters
service:
  type: "${TB_SERVICE_TYPE:tb-integration-executor}" # service type
  # Unique id for this service (autogenerated if empty)
  id: "${TB_SERVICE_ID:}"
  integrations:
    # Allow to enable integration on service/microservice integration executor. Allowed values: OCEANCONNECT, SIGFOX, THINGPARK, TPE, CHIRPSTACK, TUYA, UDP, TCP, TTN, TTI, AZURE_EVENT_HUB, OPC_UA, IBM_WATSON_IOT, AWS_IOT, AWS_SQS, LORIOT, COAP, AZURE_SERVICE_BUS, HTTP, MQTT or ALL to allow all
    supported: "${TB_SERVICE_INTEGRATIONS_SUPPORTED:ALL}"
    # List of integrations to exclude from processing on service/microservice integration executor. Allowed values: OCEANCONNECT, SIGFOX, THINGPARK, TPE, CHIRPSTACK, TUYA, UDP, TCP, TTN, TTI, AZURE_EVENT_HUB, OPC_UA, IBM_WATSON_IOT, AWS_IOT, AWS_SQS, LORIOT, COAP, AZURE_SERVICE_BUS, HTTP, MQTT. By default NONE
    excluded: "${TB_SERVICE_INTEGRATIONS_EXCLUDED:NONE}"

# Usage statistics parameters
usage:
  stats:
    report:
      # Enable/Disable the collection of statistics about API usage. Collected on a system and tenant level by default
      enabled: "${USAGE_STATS_REPORT_ENABLED:true}"
      # Enable/Disable collection of statistics about API usage on a customer level
      enabled_per_customer: "${USAGE_STATS_REPORT_PER_CUSTOMER_ENABLED:false}"
      # Interval of reporting the statistics. By default, the summarized statistics are sent every 10 seconds
      interval: "${USAGE_STATS_REPORT_INTERVAL:10}"

# Metrics parameters
metrics:
  # Enable/disable actuator metrics.
  enabled: "${METRICS_ENABLED:false}"
  timer:
    # Metrics percentiles returned by actuator for timer metrics. List of double values (divided by ,).
    percentiles: "${METRICS_TIMER_PERCENTILES:0.5}"

# General management parameters
management:
  endpoints:
    web:
      exposure:
        # Expose metrics endpoint (use value 'prometheus' to enable prometheus metrics).
        include: '${METRICS_ENDPOINTS_EXPOSE:info}'

# Notification system parameters
notification_system:
  rules:
    # Semicolon-separated deduplication durations (in millis) for trigger types. Format: 'NotificationRuleTriggerType1:123;NotificationRuleTriggerType2:456'
    deduplication_durations: "${TB_NOTIFICATION_RULES_DEDUPLICATION_DURATIONS:RATE_LIMITS:14400000;}"
